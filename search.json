[{"title":"resource1","url":"/20221203-resource1.html","content":"图片资源：\n\nhttps://wallroom.io/(强推！)\n\nhttps://wallhaven.cc/\n\nhttps://pixabay.com/\n\nhttps://www.pexels.com/\n\nhttps://unsplash.com/\n\nhttps://pic.netbian.com/\n\nhttps://bz.zzzmh.cn/index\n\nhttp://www.beiwangshan.com/wp/","tags":["资源"]},{"title":"jupyter notebook绘制高清图片","url":"/20221129-svgphoto.html","content":"在绘制一些图形时，我们往往会遇到这样一种情况，那就是在尝试把图片放大时，会出现图片模糊不清的状况，当然，这是\n非常正常的，这是由图片的格式所决定的。\n\n那么这里介绍一种格式，那就是svg,让我们绘制出的图片不再发糊！\n\n好吧，那么让我们实现这个功能！\n\n```\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\n%config InlineBackend.figure_format = 'svg'\nplt.plot([1,2,3,4],[6,5,4,3])\nplt.savefig('tmp.pdf', bbox_inches='tight')\nplt.show()\n```\n","tags":["python"]},{"title":"21cnn","url":"/20221121-21cnn.html"},{"title":"什么是git","url":"/20221121-gitstudy.html","content":"\n","tags":["git"]},{"title":"Pytorch学习笔记|CUDA 解释 - 深度学习为何使用 GPU","url":"/20221121-21text.html","content":"{% note success no-icon %}\n图形处理单元 （GPU） 提示塊標籤\n{% endnote %}\n\n要了解CUDA，我们需要具备图形处理单元（GPU）的工作知识。GPU是一种擅长处理专业计算的处理器。\n\n这与中央处理器（CPU）形成鲜明对比，中央处理器是一种擅长处理一般计算的处理器。CPU是为我们电子设备上大多数典型计算提供动力的处理器。\n\nGPU的计算速度比CPU快得多。但是，情况并非总是如此。GPU 相对于 CPU 的速度取决于所执行的计算类型。最适合 GPU 的计算类型是可以并行完成的计算。\n\n\n{% note success no-icon %}\n并行计算\n{% endnote %}\n\n并行计算是一种计算类型，其中通过特定计算被分解为可以同时执行的独立较小计算。然后，将生成的计算重新组合或同步，以形成原始较大计算的结果。\n\n![photo](/img/im1/1.png)\n\n大型任务可以分解的任务数取决于特定硬件上包含的内核数。内核是在给定处理器内实际执行计算的单元，CPU 通常具有四个、八个或十六个内核，而 GPU 可能具有数千个内核。\n\n还有其他重要的技术规范，但这种描述旨在推动总体思路。\n\n有了这些工作知识，我们可以得出结论，并行计算是使用GPU完成的，我们也可以得出结论，最适合使用GPU解决的任务是可以并行完成的任务。如果计算可以并行完成，我们可以使用并行编程方法和GPU加速计算。\n\n现在让我们把注意力转向神经网络，看看为什么GPU在深度学习中被如此频繁地使用。我们刚刚看到GPU非常适合并行计算，而关于GPU的这个事实就是深度学习使用它们的原因。\n\n在并行计算中，并行任务是几乎不需要花费或不需要任何精力将整个任务分成一组要并行计算的较小任务。\n\n令人尴尬地并行的任务是很容易看出一组较小的任务彼此独立。\n\n![photo](/img/im1/2.png)\n\n由于这个原因，神经网络是尴尬的并行。我们使用神经网络进行的许多计算可以很容易地分解成较小的计算，使得较小的计算集不相互依赖。一个这样的例子是卷积。\n\n\n{% note success no-icon %}\n卷积示例\n{% endnote %}\n\n让我们看一个例子，卷积运算：\n\n![photo](/img/im1/3.gif)\n\n此动画展示了没有数字的卷积过程。我们在底部有一个蓝色的输入通道。底部阴影的卷积滤波器在输入通道上滑动，以及绿色输出通道：\n\n    蓝色（底部）- 输入通道\n    阴影（蓝色顶部） - 3 x 3卷积核\n    绿色（顶部）- 输出通道\n\n对于蓝色输入通道上的每个位置，一个3 x 3卷积核执行计算，将蓝色输入通道的阴影部分映射到绿色输出通道的相应阴影部分。\n\n在动画中，这些计算依次发生。但是，每个计算都独立于其他计算，这意味着任何计算都不依赖于任何其他计算的结果。\n\n因此，所有这些独立计算都可以在GPU上并行进行，并且可以产生整个输出通道。\n这使我们能够看到，通过使用并行编程方法和GPU可以加速卷积操作。\n\n\n{% note success no-icon %}\nNvidia硬件 （GPU） 和软件 （CUDA）\n{% endnote %}\n\nNvidia是一家设计GPU的技术公司，他们将CUDA创建为一个软件平台，与他们的GPU硬件配对，使开发人员更容易构建使用Nvidia GPU的并行处理能力加速计算的软件。\n\n![photo](/img/im1/4.png)\n\nNvidia GPU是支持并行计算的硬件，而CUDA是为开发人员提供API的软件层。\n因此，您可能已经猜到使用CUDA需要Nvidia GPU，并且CUDA可以从Nvidia的网站免费下载和安装。\n开发人员通过下载 CUDA 工具包来使用 CUDA。随着工具包而来的是专门的库，如cuDNN，CUDA深度神经网络库。\n\n![photo](/img/im1/5.png)\n\n\n\n{% note success no-icon %}\nPyTorch 附带 CUDA\n{% endnote %}\n\n使用PyTorch或任何其他神经网络API的好处之一是，并行性融入了API中。这意味着作为神经网络程序员，我们可以更多地关注构建神经网络，而不是性能问题。\n\n有了PyTorch，CUDA从一开始就融入了。无需其他下载。我们所需要的只是有一个受支持的Nvidia GPU，我们可以使用PyTorch利用CUDA。我们不需要知道如何直接使用 CUDA API。\n\n现在，如果我们想编写PyTorch扩展，那么知道如何直接使用CUDA可能会很有用。\n毕竟，PyTorch是用所有这些编写的：\n    Python\n    C++\n    CUDA\n\n\n{% note success no-icon %}\n将 CUDA 与 PyTorch 结合使用\n{% endnote %}\n\n在PyTorch中利用CUDA非常容易。如果我们想在GPU上执行特定的计算，我们可以通过在我们的数据结构（张量）上调用cuda()来指示PyTorch这样做。\n\n假设我们有以下代码：\n\n> t = torch.tensor([1,2,3])\n> t\ntensor([1, 2, 3])\n\n默认情况下，以这种方式创建的张量对象位于 CPU 上。因此，我们使用此张量对象执行的任何操作都将在 CPU 上执行。\n现在，要将张量移动到GPU上，我们只需编写：\n\n> t = t.cuda()\n> t\ntensor([1, 2, 3], device='cuda:0')\n\n这种能力使PyTorch非常通用，因为计算可以在CPU或GPU上有选择地执行。\n\n\n{% note success no-icon %}\nGPU 可能比 CPU 慢\n{% endnote %}\n\n我们说过，我们可以有选择地在GPU或CPU上运行计算，但为什么不直接在GPU上运行每个计算呢？\n\nGPU不是比CPU快吗？\n\n答案是，GPU仅针对特定任务更快。我们可能遇到的一个问题是降低性能的瓶颈。例如，将数据从 CPU移动到 GPU 的成本很高，因此在这种情况下，如果计算任务很简单，则整体性能可能会降低。\n\n![photo](/img/im1/6.png)\n\n将相对较小的计算任务转移到GPU不会让我们加快速度，并且确实会减慢我们的速度。请记住，GPU适用于可以分解为许多较小任务的任务，如果计算任务已经很小，那么通过将任务移动到GPU，我们将没有太多收获。\n出于这个原因，在刚开始时简单地使用CPU通常是可以接受的，并且随着我们处理更大更复杂的问题，开始更多地使用GPU。\n\n\n{% note success no-icon %}\nGPGPU 计算\n{% endnote %}\n\n最初，使用GPU加速的主要任务是计算机图形学。因此得名图形处理单元，但近年来，出现了更多种类的并行任务。正如我们所看到的，其中一项任务是深度学习。\n深度学习以及许多其他使用并行编程技术的科学计算任务正在导致一种称为GPGPU或通用GPU计算的新型编程模型。\n\nGPGPU计算通常只是称为GPU计算或加速计算，因为在GPU上预制各种任务变得越来越普遍。\n\nNvidia一直是这一领域的先驱。Nvidia将通用GPU计算简称为GPU计算。Nvidia首席执行官黄仁勋（Jensen Huang）很早就设想了GPU计算，这就是为什么CUDA是在近10年前创建的。\n\n尽管CUDA已经存在了很长时间，但它现在才刚刚开始真正起飞，而Nvidia迄今为止在CUDA上的工作就是为什么Nvidia在深度学习的GPU计算方面处于领先地位。\n\n当我们听到Jensen谈论GPU计算堆栈时，他指的是GPU作为底部的硬件，CUDA作为GPU顶部的软件架构，最后是CUDA顶部的cuDNN等库。\n\n这个GPU计算堆栈是支持在一个原本非常专业的芯片上的通用计算能力。我们经常在计算机科学中看到这样的堆栈，因为技术是分层构建的，就像神经网络一样。\n坐在CUDA和cuDNN之上的是PyTorch，这是我们将要工作的框架，最终支持顶部的应用程序。\n\n本文深入探讨了GPU计算和CUDA，但它比我们需要的要深入得多。我们将在这里使用PyTorch在堆栈顶部附近工作。\n\n\n注：以上内容翻译自https://deeplizard.com/learn/video/6stDhEA0wFQ","tags":["Pytorch"]},{"title":"19text","url":"/20221119-19text.html","content":"\n![ing](/img/header-img.svg)\nweb1:\n\nweb2:\n\nweb3:\n\n","tags":["web3.0"]},{"title":"12sd","url":"/20221117-12sd.html","content":"rrrrrrrrrrrrrrcc\nccccccccccc\nxcccccccccc\n```\ndef fib(n):\n\tif n == 1:\n\t\treturn 0\n\tif n == 2:\n\t\treturn 1\n\treturn fib(n-1) + fib(n-2)\n```"},{"title":"we3","url":"/20221117-we3.html","content":"ffffffffffffff\nfrrrrrrrrrrrrrr\n```\ndef fib(n):\n\tif n == 1:\n\t\treturn 0\n\tif n == 2:\n\t\treturn 1\n\treturn fib(n-1) + fib(n-2)\n```"},{"title":"张量扁平化——CNN的Flatten操作","url":"/20221117-张量扁平化——CNN的Flatten操作.html","content":"张量扁平化操作是卷积神经网络中的一个常见操作。这是因为在全连接层接受输入之前，传递给全连接层的卷积层输出必须被扁平化。我们了解到卷积神经网络的张量输入通常有4个轴，一个用于批处理大小，一个用于颜色通道，还有一个用于高度和宽度\n\n即：(批量大小、通道、高度、宽度）\n\n\n\n图片\n\n\n\n那么现在我们以一张图片为例，看看如何将它扁平化\n\n\n\n图片\n\n\n\n \n\n这是一张彩色图片，也就是有r,g,b共三个通道，大小为128*128，按照上面的表示方法，我们可以将它表示为\n\n\n\n[1,3,128,128]\n\n\n\ncode：\n\n图片\n\n\n\n好吧，可是看到，张量已经被拉平了，达到了我们预期的目的。\n\n\n\n但是，这仅仅是一张图片，如果是二张图片呢？\n\n\n\n\n\n图片\n\n\n\n(假设仍按上述方法)\n\n\n\ncode：\n\n图片\n\n \n\n好吧，结果并不好，因为我们需要对批处理张量中的每个图像进行单独的预测，因此扁平化的批次在我们的CNN中无法很好地起作用，所以现在我们一团糟。\n\n\n\n解决方案是在保持batch 轴不变的情况下使每个图像变平。这意味着我们只想拉平张量的一部分。我们要使用高度和宽度轴和颜色通道轴展平。也就是展平(C,H,W)。\n\n\n\n假设我们有输入5张彩色的图片（也就是5张为一个batch），\n\ncode：\n\n图片\n\n\n\n结果十分符合我们所期望的。\n\n所以flatten(start_dim=1)是个较为不错的展平方法。\n\n\n\n\n\n总结：\n\n现在，我们应该对张量的展平操作有了一个很好的了解。我们知道如何展平整个张量，并且我们知道展平特定张量尺寸/轴,我们将在构建CNN时看到将其投入使用。\n\n{% note flat %}\n默認 提示塊標籤\n{% endnote %}\n\n{% note default flat %}\ndefault 提示塊標籤\n{% endnote %}\n\n{% note primary flat %}\nprimary 提示塊標籤\n{% endnote %}\n\n{% note success flat %}\nsuccess 提示塊標籤\n{% endnote %}\n\n{% note info flat %}\ninfo 提示塊標籤\n{% endnote %}\n\n{% note warning flat %}\nwarning 提示塊標籤\n{% endnote %}\n\n{% note danger flat %}\ndanger 提示塊標籤\n{% endnote %}\n\n\n{% note success no-icon %}\n```\ndef fib(n):\n\tif n == 1:\n\t\treturn 0\n\tif n == 2:\n\t\treturn 1\n\treturn fib(n-1) + fib(n-2)\n```\n{% endnote %}\n{% note blue 'fas fa-bullhorn' simple %}\n2021年快到了....\n{% endnote %}\n{% note pink 'fas fa-car-crash' simple %}\n小心開車 安全至上\n{% endnote %}\n{% note red 'fas fa-fan' simple%}\n這是三片呢？還是四片？\n{% endnote %}\n{% note orange 'fas fa-battery-half' simple %}\n你是刷 Visa 還是 UnionPay\n{% endnote %}\n{% note purple 'far fa-hand-scissors' simple %}\n剪刀石頭布\n{% endnote %}\n{% note green 'fab fa-internet-explorer' simple %}\n前端最討厭的瀏覽器\n{% endnote %}\n\n\n","tags":["深度学习"]},{"title":"cfg","url":"/20221113-cfg.html"},{"title":"我的博客","url":"/20221020-c2.html","content":"this is my blog","tags":["doc"]},{"title":"月明","url":"/20220727-f5.html","content":"# 一级标题\n\n代码测试：\n\\```py\nprint(\"Hello\")\n\\```\n\n注意：这里因为我放在md文件中的，所以加上了\\，不解析```，实际测试时请去掉\\。\n\n图片测试：\n\n\n引用测试：\n\n>这是一条引用\n\n## 二级标题\n\n无序列表测试：\n\n- 哈哈\n- 嘿嘿\n- 吼吼\n\n### 三级标题\n\n#### 四级标题\n","tags":["doc"]},{"title":"第二个博客","url":"/20220727-first.html","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","tags":["second"]},{"title":"Hello World","url":"/20220727-hello-world.html","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n"}]